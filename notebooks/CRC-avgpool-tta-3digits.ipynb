{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ffbae2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/user/anaconda3/lib/python3.9/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "2024-07-20 00:56:08.391350: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/user/anaconda3/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2024-07-20 00:56:08.391365: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import timm\n",
    "import tqdm\n",
    "\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils import data\n",
    "\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, classification_report, confusion_matrix\n",
    "from PIL import Image\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "NUM_CLASSES = 9\n",
    "BATCH_SIZE = 32\n",
    "device = torch.device(\"cuda\")\n",
    "PATH_TO_TEST_DATASET = \"data/CRC-VAL-HE-7K/\"\n",
    "\n",
    "\n",
    "def cv2_loader(path: str):\n",
    "    return Image.fromarray(cv2.imread(path, -1)[:, :, ::-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c7cb809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===============================================================================================\n",
       "Layer (type:depth-idx)                        Output Shape              Param #\n",
       "===============================================================================================\n",
       "EfficientNet                                  [1, 9]                    --\n",
       "├─Conv2d: 1-1                                 [1, 32, 112, 112]         864\n",
       "├─BatchNormAct2d: 1-2                         [1, 32, 112, 112]         64\n",
       "│    └─Identity: 2-1                          [1, 32, 112, 112]         --\n",
       "│    └─SiLU: 2-2                              [1, 32, 112, 112]         --\n",
       "├─Sequential: 1-3                             [1, 320, 7, 7]            --\n",
       "│    └─Sequential: 2-3                        [1, 16, 112, 112]         --\n",
       "│    │    └─DepthwiseSeparableConv: 3-1       [1, 16, 112, 112]         1,448\n",
       "│    │    └─DepthwiseSeparableConv: 3-2       [1, 16, 112, 112]         612\n",
       "│    └─Sequential: 2-4                        [1, 24, 56, 56]           --\n",
       "│    │    └─InvertedResidual: 3-3             [1, 24, 56, 56]           6,004\n",
       "│    │    └─InvertedResidual: 3-4             [1, 24, 56, 56]           10,710\n",
       "│    │    └─InvertedResidual: 3-5             [1, 24, 56, 56]           10,710\n",
       "│    └─Sequential: 2-5                        [1, 40, 28, 28]           --\n",
       "│    │    └─InvertedResidual: 3-6             [1, 40, 28, 28]           15,350\n",
       "│    │    └─InvertedResidual: 3-7             [1, 40, 28, 28]           31,290\n",
       "│    │    └─InvertedResidual: 3-8             [1, 40, 28, 28]           31,290\n",
       "│    └─Sequential: 2-6                        [1, 80, 14, 14]           --\n",
       "│    │    └─InvertedResidual: 3-9             [1, 80, 14, 14]           37,130\n",
       "│    │    └─InvertedResidual: 3-10            [1, 80, 14, 14]           102,900\n",
       "│    │    └─InvertedResidual: 3-11            [1, 80, 14, 14]           102,900\n",
       "│    │    └─InvertedResidual: 3-12            [1, 80, 14, 14]           102,900\n",
       "│    └─Sequential: 2-7                        [1, 112, 14, 14]          --\n",
       "│    │    └─InvertedResidual: 3-13            [1, 112, 14, 14]          126,004\n",
       "│    │    └─InvertedResidual: 3-14            [1, 112, 14, 14]          208,572\n",
       "│    │    └─InvertedResidual: 3-15            [1, 112, 14, 14]          208,572\n",
       "│    │    └─InvertedResidual: 3-16            [1, 112, 14, 14]          208,572\n",
       "│    └─Sequential: 2-8                        [1, 192, 7, 7]            --\n",
       "│    │    └─InvertedResidual: 3-17            [1, 192, 7, 7]            262,492\n",
       "│    │    └─InvertedResidual: 3-18            [1, 192, 7, 7]            587,952\n",
       "│    │    └─InvertedResidual: 3-19            [1, 192, 7, 7]            587,952\n",
       "│    │    └─InvertedResidual: 3-20            [1, 192, 7, 7]            587,952\n",
       "│    │    └─InvertedResidual: 3-21            [1, 192, 7, 7]            587,952\n",
       "│    └─Sequential: 2-9                        [1, 320, 7, 7]            --\n",
       "│    │    └─InvertedResidual: 3-22            [1, 320, 7, 7]            717,232\n",
       "│    │    └─InvertedResidual: 3-23            [1, 320, 7, 7]            1,563,600\n",
       "├─Conv2d: 1-4                                 [1, 1280, 7, 7]           409,600\n",
       "├─BatchNormAct2d: 1-5                         [1, 1280, 7, 7]           2,560\n",
       "│    └─Identity: 2-10                         [1, 1280, 7, 7]           --\n",
       "│    └─SiLU: 2-11                             [1, 1280, 7, 7]           --\n",
       "├─SelectAdaptivePool2d: 1-6                   [1, 1280]                 --\n",
       "│    └─AdaptiveAvgPool2d: 2-12                [1, 1280, 1, 1]           --\n",
       "│    └─Flatten: 2-13                          [1, 1280]                 --\n",
       "├─Linear: 1-7                                 [1, 9]                    11,529\n",
       "===============================================================================================\n",
       "Total params: 6,524,713\n",
       "Trainable params: 6,524,713\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 568.40\n",
       "===============================================================================================\n",
       "Input size (MB): 0.60\n",
       "Forward/backward pass size (MB): 74.84\n",
       "Params size (MB): 25.85\n",
       "Estimated Total Size (MB): 101.29\n",
       "==============================================================================================="
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = timm.create_model('efficientnet_b1.ft_in1k', pretrained=True, num_classes=NUM_CLASSES, in_chans=3, global_pool='avg')\n",
    "model.load_state_dict(torch.load('./0.9774_0.9688.pt'))\n",
    "model.to('cuda')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dbe2f8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_dataloader):\n",
    "    print(\"Running Evaluation...\")\n",
    "\n",
    "    targets_array = []\n",
    "    predictions_array = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        test_iter = iter(test_dataloader)\n",
    "        for j in tqdm.tqdm(range(len(test_dataloader))):\n",
    "\n",
    "            image, labels = next(test_iter)\n",
    "            image = image.to(device, non_blocking=True)\n",
    "            labels = labels.to(device, non_blocking=True)\n",
    "\n",
    "\n",
    "            predictions = model(image)\n",
    "            predictions2 = model(image.flip(2))\n",
    "            predictions3 = model(image.flip(3))\n",
    "            predictions23 = model(image.flip(2).flip(3))\n",
    "            \n",
    "            _, predictions = torch.max(predictions.data + predictions2.data + predictions3.data  + predictions23.data, 1)\n",
    "\n",
    "            predictions = predictions.detach().cpu().numpy()\n",
    "            targets = labels.detach().cpu().numpy()\n",
    "\n",
    "            for k in range(targets.shape[0]):\n",
    "\n",
    "                target = targets[k]\n",
    "                predicted = predictions[k]\n",
    "\n",
    "                targets_array.append(target)\n",
    "                predictions_array.append(predicted)\n",
    "\n",
    "        print(\"Accuracy: \" + str(accuracy_score(targets_array, predictions_array)))\n",
    "        print(\"Balanced Accuracy: \" + str(balanced_accuracy_score(targets_array, predictions_array)))\n",
    "        \n",
    "\n",
    "        print(classification_report(targets_array, predictions_array, digits=3))\n",
    "        print(confusion_matrix(targets_array, predictions_array))\n",
    "        \n",
    "        \n",
    "        return predictions_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1fc20240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 225/225 [01:00<00:00,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9772980501392757\n",
      "Balanced Accuracy: 0.9679702454961778\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.996     0.993     0.994      1338\n",
      "           1      0.999     1.000     0.999       847\n",
      "           2      0.960     0.982     0.971       339\n",
      "           3      0.975     0.997     0.986       634\n",
      "           4      0.997     0.990     0.994      1035\n",
      "           5      0.880     0.992     0.932       592\n",
      "           6      0.989     0.976     0.982       741\n",
      "           7      0.955     0.808     0.875       421\n",
      "           8      0.984     0.975     0.980      1233\n",
      "\n",
      "    accuracy                          0.977      7180\n",
      "   macro avg      0.971     0.968     0.968      7180\n",
      "weighted avg      0.978     0.977     0.977      7180\n",
      "\n",
      "[[1328    1    0    0    0    9    0    0    0]\n",
      " [   0  847    0    0    0    0    0    0    0]\n",
      " [   0    0  333    0    0    1    0    5    0]\n",
      " [   0    0    1  632    0    0    0    1    0]\n",
      " [   6    0    0    0 1025    0    0    1    3]\n",
      " [   0    0    0    0    0  587    0    5    0]\n",
      " [   0    0    0    2    2    0  723    0   14]\n",
      " [   0    0    2    3    0   70    4  340    2]\n",
      " [   0    0   11   11    1    0    4    4 1202]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_transforms = transforms.Compose([transforms.ToTensor(), transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "test_dataset = datasets.ImageFolder(PATH_TO_TEST_DATASET, transform=test_transforms, loader=cv2_loader)\n",
    "test_dataloader = data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=False, drop_last=False)\n",
    "\n",
    "predictions_no_hue_aug = evaluate(model, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c44d4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
